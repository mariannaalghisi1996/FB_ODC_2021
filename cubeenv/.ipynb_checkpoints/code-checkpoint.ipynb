{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import shutil \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridData(csvfiles):\n",
    "    # Definition of the paths to folders and files:\n",
    "    grid_path = 'C:/git/FB_ODC_2021/griglia_csv/GRIGLIA_MILANO.csv'  \n",
    "    path_to_netcdf_folder = 'C:/git/FB_ODC_2021/netcdf_files'\n",
    "    origin = 'C:/git/FB_ODC_2021/empty_yaml.yaml'\n",
    "    \n",
    "    # Upload the grid \n",
    "    grid = pd.read_csv(grid_path)\n",
    "    \n",
    "    #  All the csv are loaded as pandas dataframe, then are joined to the grid on quadkey value \n",
    "    gridded_csv = []\n",
    "    \n",
    "    for i in range(len(csvfiles)):\n",
    "        # Temporary dataframe, from csv\n",
    "        temp_df = pd.read_csv(csvfiles[i])\n",
    "        # Not necessary columns are dropped\n",
    "        temp_df = temp_df.drop(columns = ['country','lon', 'lat', 'n_baseline', 'n_difference', 'density_crisis', 'density_baseline', 'percent_change', 'clipped_z_score', 'ds'])\n",
    "        # nan values are set to 0\n",
    "        temp_df['n_crisis'] = temp_df['n_crisis'].replace( '\\\\N', 0)\n",
    "        temp_df['n_crisis'] = temp_df['n_crisis'].astype(float)\n",
    "        \n",
    "        # merge of the csv with the grid on quadkey\n",
    "        temp_gridded = grid.merge(temp_df, on = 'quadkey', how = 'outer')\n",
    "        temp_gridded = temp_gridded.rename(columns = {'latitude_g':'latitude', 'longitude_g':'longitude'})\n",
    "        temp_gridded['n_crisis'].fillna(0, inplace=True)\n",
    "      \n",
    "        # Datetimes are used to name the NETCDF files\n",
    "        date_time = (((csvfiles[i].split('_'))[3]).split('.'))[0]  \n",
    "        temp_gridded['date_time'] = datetime\n",
    "        temp_gridded = temp_gridded.set_index(['quadkey'])\n",
    "        # all gridded csv are stored in gridded_csv list of dataframe\n",
    "        gridded_csv.append(temp_gridded)\n",
    "        print('ok',i,'gridded')\n",
    "        \n",
    "        # Gridded dataframes are transformed in xarray\n",
    "        temp_xarray = temp_gridded.to_xarray()\n",
    "        print('ok',i,'to xarray')\n",
    "        \n",
    "        # xarray are transformed to netcdf files and saved in a specific folder\n",
    "        netcdf_path = path_to_netcdf_folder+'/'+datetime+'.nc'\n",
    "        temp_xarray.to_netcdf(netcdf_path)\n",
    "        print('ok',i,'in netcdf')\n",
    "    \n",
    "        # Writing of the metadata on a yaml file\n",
    "        datetime_string = datetime[0:10]+\"T\"+datetime[11]+datetime[12]+\":\"+datetime[13]+datetime[14]+\":00.000Z\"\n",
    "        PID = list(datetime)\n",
    "        PID.remove(\"-\")\n",
    "        PID.remove(\"-\")\n",
    "        PID.remove(\" \")\n",
    "        PID = \"\".join(PID)\n",
    "        file1 = open(origin, \"w\")\n",
    "        to_write = \"$schema: https://schemas.opendatacube.org/dataset \\n \\nid: 00000000-0000-0000-0000-\"+PID+\"\\n\\nproduct:\\n  name: FB_POI_MILANO\\n  href: https://dataforgood.fb.com/ \\n  format: NetCDF\\n\\ncrs: epsg:4326\\n\\ngeometry:\\n  type: Polygon\\n  coordinates: [[[ 8.995056152343800, 45.311597470877999], [8.995056152343800, 45.627484179430269], [9.549865722656120, 45.627484179430269], [9.549865722656120, 45.311597470877999], [ 8.995056152343800, 45.311597470877999]]]\\n\\ngrids:\\n  default:\\n    shape: [102,83] \\n    transform: [1,0,0,0,1,0,0,0,1]\\n\\nlineage: {}\\n\\nmeasurements:\\n  n_crisis:\\n    layer: n_crisis\\n    path: \"+netcdf_path+\"\\n    nodata: -9999\\n\\nproperties:\\n  odc:file_format: NetCDF\\n  datetime: \"+datetime_string\n",
    "        file1.write(to_write)\n",
    "        file1.close()\n",
    "        target = \"C:/git/FB_ODC_2021/cubeenv/dataset/\"+PID+\".yaml\"\n",
    "        # shutil library is used to save a copy of the file in the folder containing all metadata\n",
    "        shutil.copy(origin, target)\n",
    "        \n",
    "        command = \"datacube dataset add \"+ target\n",
    "        os.system(command)\n",
    "        \n",
    "    # In conclusion the names of the new peocessed csv are now written in loaded_csv.txt \n",
    "    to_write_on_txt = \",\".join(csvfiles)+','\n",
    "    with open(\"loaded_csv.txt\", \"a\") as output:\n",
    "        output.write(to_write_on_txt)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return 'DONE!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No new csv have been found, all csv are already uploaded in ODC\n"
     ]
    }
   ],
   "source": [
    "# Check if there are new csv files in /Coronavirus Disease Prevention/Population Map/milan to upload in OpenDataCube\n",
    "fold_path = 'C:/git/FB_ODC_2021/milan'\n",
    "csvfiles = []\n",
    "for file in glob.glob(fold_path+\"/\"+\"*.csv\"):\n",
    "    # We only consider not-empy files\n",
    "    if os.stat(file).st_size != 0:\n",
    "        csvfiles.append(file)\n",
    "\n",
    "# 'loadedCSV.txt' contains all the names of the already loaded files, already_loaded is a list containing these files names\n",
    "with open(\"C:/git/FB_ODC_2021/loaded_csv.txt\", \"r\") as txt:\n",
    "    already_loaded = (txt.read()).split(',')\n",
    "\n",
    "# in order to check if there are new csv i use a loop that removes from csvfiles list the names of the already loaded csv\n",
    "for name in already_loaded:\n",
    "    if name in csvfiles:\n",
    "        csvfiles.remove(name)  \n",
    "\n",
    "if len(csvfiles) != 0:\n",
    "    print(len(csvfiles), 'new CSVs have been found')\n",
    "    print('Processing of CSVs is started...')\n",
    "    ret = gridData(csvfiles)\n",
    "    if ret == 'DONE!':\n",
    "        print('CSVs have been processed and transformed in NETCDF format, metadata dataset have been created and correctly uploaded in ODC')\n",
    "        \n",
    "    else:\n",
    "        print('Something whent wrong :(')\n",
    "else:\n",
    "    print('No new csv have been found, all csv are already uploaded in ODC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General information about ODC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datacube\n",
    "#from odc.ui import DcViewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maria\\anaconda3\\envs\\cubeenv\\lib\\site-packages\\datacube\\drivers\\postgres\\_connections.py:84: SADeprecationWarning: Calling URL() directly is deprecated and will be disabled in a future release.  The public constructor for URL is now the URL.create() method.\n",
      "  username=username, password=password,\n"
     ]
    }
   ],
   "source": [
    "dc = datacube.Datacube(app = \"FB_ODC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>platform</th>\n",
       "      <th>instrument</th>\n",
       "      <th>crs</th>\n",
       "      <th>resolution</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>prova_1</td>\n",
       "      <td>FB for good data about population</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>EPSG:4326</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       name                        description platform instrument        crs  \\\n",
       "id                                                                              \n",
       "1   prova_1  FB for good data about population     None       None  EPSG:4326   \n",
       "\n",
       "   resolution  \n",
       "id             \n",
       "1        None  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display all products contained in ODC database\n",
    "list_of_products = dc.list_products()\n",
    "products = dc.list_products()\n",
    "display_columns = [\"name\",\n",
    "                   \"description\",\n",
    "                   \"platform\",\n",
    "                   \"instrument\",\n",
    "                   \"crs\",\n",
    "                   \"resolution\"]\n",
    "\n",
    "products[display_columns].sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>dtype</th>\n",
       "      <th>units</th>\n",
       "      <th>nodata</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>measurement</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>n_crisis</th>\n",
       "      <td>n_crisis</td>\n",
       "      <td>float64</td>\n",
       "      <td>people</td>\n",
       "      <td>-9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quadkey</th>\n",
       "      <td>quadkey</td>\n",
       "      <td>int64</td>\n",
       "      <td>adimentional</td>\n",
       "      <td>-9999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 name    dtype         units  nodata\n",
       "measurement                                         \n",
       "n_crisis     n_crisis  float64        people   -9999\n",
       "quadkey       quadkey    int64  adimentional   -9999"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select a specific product and show it's characteri\n",
    "product = 'prova_1'\n",
    "measurements = dc.list_measurements()\n",
    "measurements.loc[product]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd2da09768a244a0adf785fe95d37abb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Dropdown(layout=Layout(flex='0 1 auto', width='10em'), options=('Population_MI',…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DcViewer(dc=dc,\n",
    "         time='2020',\n",
    "         width='800px',\n",
    "         center=(45.469, 9.265),\n",
    "         zoom=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "zip argument #2 must support iteration",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-f72e091a8c63>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mlatitude_bounds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m45.311597470877999\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m45.627484179430269\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mlongitude_bounds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m8.995056152343800\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m9.549865722656120\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproduct\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'prova_1'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlatitude\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlatitude_bounds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlongitude\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlongitude_bounds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'2020'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresolution\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\cubeenv\\lib\\site-packages\\datacube\\api\\core.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(self, product, measurements, output_crs, resolution, resampling, skip_broken_datasets, dask_chunks, like, fuse_func, align, datasets, progress_cbk, **query)\u001b[0m\n\u001b[0;32m    302\u001b[0m         geobox = output_geobox(like=like, output_crs=output_crs, resolution=resolution, align=align,\n\u001b[0;32m    303\u001b[0m                                \u001b[0mgrid_spec\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdatacube_product\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrid_spec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 304\u001b[1;33m                                datasets=datasets, **query)\n\u001b[0m\u001b[0;32m    305\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m         \u001b[0mgroup_by\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mquery_group_by\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cubeenv\\lib\\site-packages\\datacube\\api\\core.py\u001b[0m in \u001b[0;36moutput_geobox\u001b[1;34m(like, output_crs, resolution, align, grid_spec, datasets, geopolygon, **query)\u001b[0m\n\u001b[0;32m    666\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Product has no default resolution. Must specify 'resolution'\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    667\u001b[0m             \u001b[0mresolution\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresolution\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 668\u001b[1;33m         \u001b[0malign\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malign\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mgrid_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malignment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    669\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mgeopolygon\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cubeenv\\lib\\site-packages\\datacube\\model\\__init__.py\u001b[0m in \u001b[0;36malignment\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    615\u001b[0m         \u001b[0mPixel\u001b[0m \u001b[0mboundary\u001b[0m \u001b[0malignment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    616\u001b[0m         \"\"\"\n\u001b[1;32m--> 617\u001b[1;33m         \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0morig\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0morig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0morigin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresolution\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    618\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    619\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: zip argument #2 must support iteration"
     ]
    }
   ],
   "source": [
    "#from odc.ui import with_ui_cbk\n",
    "\n",
    "# The function dc.load allows to load all dataset from 'FB_POP_MILANO' that matches the given spatial and temporal extent\n",
    "latitude_bounds = (45.311597470877999, 45.627484179430269)\n",
    "longitude_bounds = (8.995056152343800, 9.549865722656120)\n",
    "ds = dc.load(product='prova_1', latitude=latitude_bounds, longitude=longitude_bounds, time = '2020', resolution = (-10,10), output_crs='EPSG:4326')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  ()\n",
      "Data variables:\n",
      "    *empty*\n"
     ]
    }
   ],
   "source": [
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import python_utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
