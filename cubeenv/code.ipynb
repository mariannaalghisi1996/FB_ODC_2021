{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import shutil \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridData(csvfiles):\n",
    "    # Definition of the paths to folders and files:\n",
    "    grid_path = 'C:/git/FB_ODC_2021/griglia_csv/GRIGLIA_MILANO.csv'  \n",
    "    path_to_netcdf_folder = 'C:/git/FB_ODC_2021/netcdf_files'\n",
    "    origin = 'C:/git/FB_ODC_2021/empty_yaml.yaml'\n",
    "    \n",
    "    # Upload the grid \n",
    "    grid = pd.read_csv(grid_path)\n",
    "    \n",
    "    #  All the csv are loaded as pandas dataframe, then are joined to the grid on quadkey value \n",
    "    gridded_csv = []\n",
    "    \n",
    "    for i in range(len(csvfiles)):\n",
    "        # Temporary dataframe, from csv\n",
    "        temp_df = pd.read_csv(csvfiles[i])\n",
    "        # Not necessary columns are dropped\n",
    "        temp_df = temp_df.drop(columns = ['country','lon', 'lat', 'n_baseline', 'n_difference', 'density_crisis', 'density_baseline', 'percent_change', 'clipped_z_score', 'ds'])\n",
    "        # nan values are set to 0\n",
    "        temp_df['n_crisis'] = temp_df['n_crisis'].replace( '\\\\N', 0)\n",
    "        temp_df['n_crisis'] = temp_df['n_crisis'].astype(float)\n",
    "        \n",
    "        # merge of the csv with the grid on quadkey\n",
    "        temp_gridded = grid.merge(temp_df, on = 'quadkey', how = 'outer')\n",
    "        temp_gridded = temp_gridded.rename(columns = {'latitude_g':'latitude', 'longitude_g':'longitude'})\n",
    "        temp_gridded['n_crisis'].fillna(0, inplace=True)\n",
    "      \n",
    "        # Datetimes are used to name the NETCDF files\n",
    "        date_time = (((csvfiles[i].split('_'))[3]).split('.'))[0]  \n",
    "        temp_gridded['date_time'] = datetime\n",
    "        temp_gridded = temp_gridded.set_index(['quadkey'])\n",
    "        # all gridded csv are stored in gridded_csv list of dataframe\n",
    "        gridded_csv.append(temp_gridded)\n",
    "        print('ok',i,'gridded')\n",
    "        \n",
    "        # Gridded dataframes are transformed in xarray\n",
    "        temp_xarray = temp_gridded.to_xarray()\n",
    "        print('ok',i,'to xarray')\n",
    "        \n",
    "        # xarray are transformed to netcdf files and saved in a specific folder\n",
    "        netcdf_path = path_to_netcdf_folder+'/'+datetime+'.nc'\n",
    "        temp_xarray.to_netcdf(netcdf_path)\n",
    "        print('ok',i,'in netcdf')\n",
    "    \n",
    "        # Writing of the metadata on a yaml file\n",
    "        datetime_string = datetime[0:10]+\"T\"+datetime[11]+datetime[12]+\":\"+datetime[13]+datetime[14]+\":00.000Z\"\n",
    "        PID = list(datetime)\n",
    "        PID.remove(\"-\")\n",
    "        PID.remove(\"-\")\n",
    "        PID.remove(\" \")\n",
    "        PID = \"\".join(PID)\n",
    "        file1 = open(origin, \"w\")\n",
    "        to_write = \"$schema: https://schemas.opendatacube.org/dataset \\n \\nid: 00000000-0000-0000-0000-\"+PID+\"\\n\\nproduct:\\n  name: FB_POI_MILANO\\n  href: https://dataforgood.fb.com/ \\n  format: NetCDF\\n\\ncrs: epsg:4326\\n\\ngeometry:\\n  type: Polygon\\n  coordinates: [[[ 8.995056152343800, 45.311597470877999], [8.995056152343800, 45.627484179430269], [9.549865722656120, 45.627484179430269], [9.549865722656120, 45.311597470877999], [ 8.995056152343800, 45.311597470877999]]]\\n\\ngrids:\\n  default:\\n    shape: [102,83] \\n    transform: [1,0,0,0,1,0,0,0,1]\\n\\nlineage: {}\\n\\nmeasurements:\\n  n_crisis:\\n    layer: n_crisis\\n    path: \"+netcdf_path+\"\\n    nodata: -9999\\n\\nproperties:\\n  odc:file_format: NetCDF\\n  datetime: \"+datetime_string\n",
    "        file1.write(to_write)\n",
    "        file1.close()\n",
    "        target = \"C:/git/FB_ODC_2021/cubeenv/dataset/\"+PID+\".yaml\"\n",
    "        # shutil library is used to save a copy of the file in the folder containing all metadata\n",
    "        shutil.copy(origin, target)\n",
    "        \n",
    "        command = \"datacube dataset add \"+ target\n",
    "        os.system(command)\n",
    "        \n",
    "    # In conclusion the names of the new peocessed csv are now written in loaded_csv.txt \n",
    "    to_write_on_txt = \",\".join(csvfiles)+','\n",
    "    with open(\"loaded_csv.txt\", \"a\") as output:\n",
    "        output.write(to_write_on_txt)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return 'DONE!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No new csv have been found, all csv are already uploaded in ODC\n"
     ]
    }
   ],
   "source": [
    "# Check if there are new csv files in /Coronavirus Disease Prevention/Population Map/milan to upload in OpenDataCube\n",
    "fold_path = 'C:/git/FB_ODC_2021/milan'\n",
    "csvfiles = []\n",
    "for file in glob.glob(fold_path+\"/\"+\"*.csv\"):\n",
    "    # We only consider not-empy files\n",
    "    if os.stat(file).st_size != 0:\n",
    "        csvfiles.append(file)\n",
    "\n",
    "# 'loadedCSV.txt' contains all the names of the already loaded files, already_loaded is a list containing these files names\n",
    "with open(\"C:/git/FB_ODC_2021/loaded_csv.txt\", \"r\") as txt:\n",
    "    already_loaded = (txt.read()).split(',')\n",
    "\n",
    "# in order to check if there are new csv i use a loop that removes from csvfiles list the names of the already loaded csv\n",
    "for name in already_loaded:\n",
    "    if name in csvfiles:\n",
    "        csvfiles.remove(name)  \n",
    "\n",
    "if len(csvfiles) != 0:\n",
    "    print(len(csvfiles), 'new CSVs have been found')\n",
    "    print('Processing of CSVs is started...')\n",
    "    ret = gridData(csvfiles)\n",
    "    if ret == 'DONE!':\n",
    "        print('CSVs have been processed and transformed in NETCDF format, metadata dataset have been created and correctly uploaded in ODC')\n",
    "        \n",
    "    else:\n",
    "        print('Something whent wrong :(')\n",
    "else:\n",
    "    print('No new csv have been found, all csv are already uploaded in ODC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General information about ODC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datacube\n",
    "#from odc.ui import DcViewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maria\\anaconda3\\envs\\cubeenv\\lib\\site-packages\\datacube\\drivers\\postgres\\_connections.py:84: SADeprecationWarning: Calling URL() directly is deprecated and will be disabled in a future release.  The public constructor for URL is now the URL.create() method.\n",
      "  username=username, password=password,\n"
     ]
    }
   ],
   "source": [
    "dc = datacube.Datacube(app = \"FB_ODC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>platform</th>\n",
       "      <th>instrument</th>\n",
       "      <th>crs</th>\n",
       "      <th>resolution</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>prova_1</td>\n",
       "      <td>FB for good data about population</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>EPSG:4326</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       name                        description platform instrument        crs  \\\n",
       "id                                                                              \n",
       "1   prova_1  FB for good data about population     None       None  EPSG:4326   \n",
       "\n",
       "   resolution  \n",
       "id             \n",
       "1        None  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display all products contained in ODC database\n",
    "list_of_products = dc.list_products()\n",
    "products = dc.list_products()\n",
    "display_columns = [\"name\",\n",
    "                   \"description\",\n",
    "                   \"platform\",\n",
    "                   \"instrument\",\n",
    "                   \"crs\",\n",
    "                   \"resolution\"]\n",
    "\n",
    "products[display_columns].sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>dtype</th>\n",
       "      <th>units</th>\n",
       "      <th>nodata</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>measurement</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>n_crisis</th>\n",
       "      <td>n_crisis</td>\n",
       "      <td>float64</td>\n",
       "      <td>people</td>\n",
       "      <td>-9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quadkey</th>\n",
       "      <td>quadkey</td>\n",
       "      <td>int64</td>\n",
       "      <td>adimentional</td>\n",
       "      <td>-9999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 name    dtype         units  nodata\n",
       "measurement                                         \n",
       "n_crisis     n_crisis  float64        people   -9999\n",
       "quadkey       quadkey    int64  adimentional   -9999"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select a specific product and show it's characteri\n",
    "product = 'prova_1'\n",
    "measurements = dc.list_measurements()\n",
    "measurements.loc[product]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd2da09768a244a0adf785fe95d37abb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Dropdown(layout=Layout(flex='0 1 auto', width='10em'), options=('Population_MI',â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DcViewer(dc=dc,\n",
    "         time='2020',\n",
    "         width='800px',\n",
    "         center=(45.469, 9.265),\n",
    "         zoom=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maria\\anaconda3\\envs\\cubeenv\\lib\\site-packages\\rasterio\\__init__.py:220: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix be returned.\n",
      "  s = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n",
      "C:\\Users\\maria\\anaconda3\\envs\\cubeenv\\lib\\site-packages\\datacube\\storage\\_rio.py:191: DeprecationWarning: Broken/missing geospatial data was found in file:\n",
      "\"NetCDF:\"C:\\git\\FB_ODC_2021\\netcdf_files\\2020-04-050000.nc\":n_crisis\"\n",
      "Will use approximate metadata for backwards compatibility reasons (#673).\n",
      "This behaviour is deprecated. Future versions will raise an error.\n",
      "  category=DeprecationWarning)\n",
      "C:\\Users\\maria\\anaconda3\\envs\\cubeenv\\lib\\site-packages\\datacube\\storage\\_rio.py:191: DeprecationWarning: Broken/missing geospatial data was found in file:\n",
      "\"NetCDF:\"C:\\git\\FB_ODC_2021\\netcdf_files\\2020-04-050800.nc\":n_crisis\"\n",
      "Will use approximate metadata for backwards compatibility reasons (#673).\n",
      "This behaviour is deprecated. Future versions will raise an error.\n",
      "  category=DeprecationWarning)\n",
      "C:\\Users\\maria\\anaconda3\\envs\\cubeenv\\lib\\site-packages\\datacube\\storage\\_rio.py:191: DeprecationWarning: Broken/missing geospatial data was found in file:\n",
      "\"NetCDF:\"C:\\git\\FB_ODC_2021\\netcdf_files\\2020-04-051600.nc\":n_crisis\"\n",
      "Will use approximate metadata for backwards compatibility reasons (#673).\n",
      "This behaviour is deprecated. Future versions will raise an error.\n",
      "  category=DeprecationWarning)\n",
      "C:\\Users\\maria\\anaconda3\\envs\\cubeenv\\lib\\site-packages\\datacube\\storage\\_rio.py:191: DeprecationWarning: Broken/missing geospatial data was found in file:\n",
      "\"NetCDF:\"C:\\git\\FB_ODC_2021\\netcdf_files\\2020-04-060000.nc\":n_crisis\"\n",
      "Will use approximate metadata for backwards compatibility reasons (#673).\n",
      "This behaviour is deprecated. Future versions will raise an error.\n",
      "  category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#from odc.ui import with_ui_cbk\n",
    "\n",
    "# The function dc.load allows to load all dataset from 'FB_POP_MILANO' that matches the given spatial and temporal extent\n",
    "latitude_bounds = (45.311597470877999, 45.627484179430269)\n",
    "longitude_bounds = (8.995056152343800, 9.549865722656120)\n",
    "ds = dc.load(product='prova_1', \n",
    "             measurements = ['n_crisis'],\n",
    "             time = '2020', \n",
    "             crs = 'EPSG:4326',\n",
    "             resolution = (-0.001, 0.001), \n",
    "             output_crs='EPSG:4326',\n",
    "             resampling='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:      (time: 4, latitude: 317, longitude: 555)\n",
      "Coordinates:\n",
      "  * time         (time) datetime64[ns] 2020-04-05 ... 2020-04-06\n",
      "  * latitude     (latitude) float64 45.63 45.63 45.63 ... 45.31 45.31 45.31\n",
      "  * longitude    (longitude) float64 8.996 8.997 8.998 ... 9.548 9.549 9.55\n",
      "    spatial_ref  int32 4326\n",
      "Data variables:\n",
      "    n_crisis     (time, latitude, longitude) float64 58.47 58.47 ... 65.82 65.82\n",
      "Attributes:\n",
      "    crs:           EPSG:4326\n",
      "    grid_mapping:  spatial_ref\n"
     ]
    }
   ],
   "source": [
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "latitude_extents = (min(ds['latitude'].values),max(ds['latitude'].values))\n",
    "longitude_extents = (min(ds['longitude'].values),max(ds['longitude'].values))\n",
    "time_extents = (min(ds['time'].values),max(ds['time'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45.311499999999995, 45.6275)\n",
      "(8.995500000000002, 9.549500000000002)\n",
      "(numpy.datetime64('2020-04-05T00:00:00.000000000'), numpy.datetime64('2020-04-06T00:00:00.000000000'))\n"
     ]
    }
   ],
   "source": [
    "print(latitude_extents)\n",
    "print(longitude_extents)\n",
    "print(time_extents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-13f3a4598920>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'n_crisis'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "min(ds['n_crisis'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
